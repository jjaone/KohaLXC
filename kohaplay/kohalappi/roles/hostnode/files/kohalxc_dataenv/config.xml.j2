<?xml version="1.0" encoding="UTF-8"?>
<!-- KohaLXC/kohatools (data+mmtenv): PP/MMT-configuration
file: $KOHALXC_TOOLDIR/ppmmtws/{{ item.name }}.xml
{{ ansible_managed | comment }}
-->
<config>
  <!-- For PP/MMT-usage in w/ kohalxc/kohatools/ansible: KohaLappi-case (kohalappi) -->
    <sourceDataDirectory>{{ item.source }}/</sourceDataDirectory>
    <preprocessedFolder>{{ item.source }}/preprocessed/</preprocessedFolder>
    <targetDataDirectory>{{ item.source }}/target/</targetDataDirectory>

    <openilsDirectory>/openils/</openilsDirectory>
    <!--How many extra processes are launched? 0 disables multithreading -->
    <threadCount>{{ item.threadCount | d(0) }}</threadCount> <!-- PatronImportChain throws segmentation fault, so keep this disabled -->
    <organization>{{ item.organization | d('lappi') | lower }}</organization>
    <!-- We are migrating '(koha)lappi' now -->

    <!-- Debug related parameters, set to -1 if no debugging required -->
    <DEBUGAuthoritiesCountLimit>{{ item.debugACL | d(-7000) }}</DEBUGAuthoritiesCountLimit>

    <!-- Do we separate volatile objects to a volatile-file, or push them to Evergreen database, org_unit "KONVERSIO"? -->
    <MigrateVolatile>1</MigrateVolatile> <!--  valid settings are [ 0 , 1 ] -->

    <!-- Batch management -->
    <ChunkSize>{{ item.chunkSize | d(5000) }}</ChunkSize>   <!-- How many records does each licmarca-chunk contain? Maximum chunks/sourceFile = 10000 -->
    <StartingChunk>{{ item.startingChunk | d(0) }}</StartingChunk>    <!-- From which chunk to start? -->
    <EndingChunk>{{ item.endingChunk | d(-1) }}</EndingChunk>     <!-- To which chunk to end, exclusive! Chunk you set won"t get processed. -1 to process all. -->
    <!-- Component parts will claim their docId"s starting  from this value, so it must be one higher than the highest docId in importable licmarca.kir -->
    <!-- If set to 0, MasterMigrationTool will find the biggest docId from the sorted-by-docid licmarca.kir. -->

    <!-- Should we read external repositories such as ONKI, YSA, KAUNOKKI etc. -->
    <LoadExternalRepositories>{{ item.loadExternalRepos | d(0) }}</LoadExternalRepositories>
    
    <BibliosImportChain>

        <!-- Program phase control variables -->
        <!-- Processing datasets for database INSERTion -->
        <doRun>{{ item.biblios_run | d(1) }}</doRun>
        <PreProcess>{{ item.preprocess }}</PreProcess>
        <BuildMARC>1</BuildMARC>
        <RunUSEMARCON>1</RunUSEMARCON>

        <NextFreeDocId>1</NextFreeDocId>
        <MaxWordLength>750</MaxWordLength> <!-- Subfields longer than this are truncated to this length. -->
        <MaxRecordLength>75000</MaxRecordLength>

        <UsemarconLog>logs/usemarcon.log</UsemarconLog>
    </BibliosImportChain>

    <ItemsImportChain>
        <!-- Processing datasets for database INSERTion -->
        <doRun>{{ item.items_run | d(1) }}</doRun>
        <PreProcess>1</PreProcess>
        <BuildItems>1</BuildItems>
    </ItemsImportChain>

    <HoldsImportChain>
        <doRun>{{ item.holds_run | d(1) }}</doRun>
        <PreProcess>1</PreProcess>
        <BuildHolds>1</BuildHolds>
    </HoldsImportChain>

    <FinesImportChain>
        <doRun>{{ item.fines_run | d(1) }}</doRun>
        <PreProcess>1</PreProcess>
        <Build>1</Build>
    </FinesImportChain>

    <PatronsImportChain>
        <!-- Processing datasets for database INSERTion -->
        <doRun>{{ item.patrons_run | d(1) }}</doRun>
        <PreProcess>1</PreProcess>
        <BuildPatrons>1</BuildPatrons>
        <!-- Should we censor the data or not? Used by the Patron-object . -->
        <Censor>0</Censor>
        <FreeSSNStoreIndex>{{ item.patrons_ssnindex | d(120000) }}</FreeSSNStoreIndex>
    </PatronsImportChain>

    <CheckOutsImportChain>
        <!-- Processing datasets for database INSERTion -->
        <doRun>{{ item.checkouts_run | d(1) }}</doRun>
        <PreProcess>1</PreProcess>
        <BuildCheckOuts>1</BuildCheckOuts>
    </CheckOutsImportChain>

    <HistoryImportChain>
        <!-- Processing datasets for database INSERTion -->
        <doRun>{{ item.history_run | d(1) }}</doRun>
        <PreProcess>1</PreProcess>
        <BuildHistory>1</BuildHistory>
    </HistoryImportChain>

    <PreProcess>
        <CharacterEncodings>
            <DEFAULT>LATIN1</DEFAULT>
            <lilcust.kir>LATIN1</lilcust.kir>
            <licmarca.kir>ISO_6937-2</licmarca.kir>
            <licinfoa.kir>ISO_6937-2</licinfoa.kir>
            <licauthp.kir>ISO_6937-2</licauthp.kir>
            <licauthc.kir>ISO_6937-2</licauthc.kir>
            <licauths.kir>ISO_6937-2</licauths.kir>
        </CharacterEncodings>
    </PreProcess>

    <SerialsImportChain>
        <doRun>{{ item.serials_run | d(0) }}</doRun>
        <!-- <PreProcess>1</PreProcess> PreProcessing is performed in BibliosImportChain-->
        <serialMotherFolder>Serials/</serialMotherFolder>
        <serialMotherFile>serialmothers.marc</serialMotherFile>
        <serialIssueFile>serials.marc</serialIssueFile>

        <serialItemFolder>SerialItems/</serialItemFolder>
        <serialItemFile>serials.item</serialItemFile>
    </SerialsImportChain>

</config>
