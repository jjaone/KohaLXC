---
# File: roles/hostnode/tasks/srvenv-setup.yaml
# #############################################################################
# Code is part of the KohaLXC/kohatools Ansible/Bash tooling environment
# for Koha/ILS-development, deployment & database conversion/migration tasks.
# Author: Jukka Aaltonen, Koha-Lappi, Rovaniemi City Library, Lapland/Finland.
# License: GNU General Public License version 3.
# 
# Description: server environment setup tasks
# - setup hostnodes server-environment in playbook inventories
# - prepare dialogless installation of listed packages
# - ensure availability of all required distro packages
# - check/create users and groups for server (and development) environments
# - setup localization (locale, timezone?) and (development) shell profile
# - prepare KohaLXC-tools environment (directories & perms)
# - handle network configuration and traffic rules (iptables) persistence
# - distro package cache, server upgrades, updates and reboot support
# [TODO]:
# - OS, distro, kernel (base installation of Ubuntu 16.04 LTS Server)
# - filesystems and storage: lvm, btrfs, zfs
# - network: interfaces and iptables rules + persistence, SSL
# - server monitoring and backups
# ##############################################################################

## Pre-seed debconf (to prevent install dialogs) for select packages
# [KohaLXC]: srvenv: preseeded and dialogless installation (for listed pckgs)
- name: For select packages 'debconf' pre-seed installation settings
  become: yes
  debconf:
    name: "{{ item.name }}"
    setting: "{{ item.name }}/{{ item.q }}"
    vtype: "{{ item.type }}"
    value: "{{ item.value}}"
  with_items:
    - { name: iptables-persistent, q: autosave_v4, type: boolean, value: true }
    - { name: iptables-persistent, q: autosave_v6, type: boolean, value: true }

## Ensure env.* pckgs are installed
# [KohaLXC]: srvenv: Packages for server environment
- name: srvenv - Ensure all needed packages are installed
  become: yes
  apt: >
    name="{{ item }}"
    update_cache="yes"
    state="present"
    autoremove="yes"
  with_flattened:
    - "{{ hostnode_srvenv_enabled | ternary(hostnode_srvenv_pckgs, '') }}"
    - "{{ hostnode_secure_enabled | ternary(hostnode_secure_pckgs, '' ) }}"
    - "{{ hostnode_lvm_enabled | ternary(hostnode_lvm_pckgs, '') }}"
  when:
    - hostnode_srvenv_enabled or hostnode_secure_enabled or hostnode_lvm_enabled
    - item is defined and item != ''

## Ensure 'kohasys'-user exists (by default: kohasys/1000)
- name: srvenv - Make system user 'kohasys' for Koha/hosts-service management
  become: yes
  user: >
    name="{{ hostnode_kohasys_user }}"
    uid="{{ hostnode_kohasys_id }}"
    state="present"
    generate_ssh_key="yes"
    comment="Koha/host system user"
  when:
    - hostnode_kohasys_user is defined
    - hostnode_kohasys_id is defined

## Ensure devops (kohaoper/1002) belongs to 'koha' group and has ssh-keys
- name: srvenv - Ensure devops has ssh-keys and belongs to 'koha' group
  become: yes
  user: >
    name="{{ hostnode_operuser }}"
    uid="{{ hostnode_operid }}"
    groups="{{ hostnode_kohagrp_name }}"
    append="yes"
    generate_ssh_key="yes"
    comment="Koha/LXC devops user"
  when:
    - hostnode_operuser is defined
    - hostnode_operid is defined
    - hostnode_kohagrp_name is defined

## Ensure locales we need are present
- name: srvenv - Ensure needed locales for internationalization are present
  become: yes
  locale_gen:
    name: "{{ item }}"
    state: present
  with_items:
    - en_US.UTF-8
    - fi_FI.UTF-8

- debug: var=hostnode_environment,kohalxc_install,kohalxc_tooldir,kohalxc_organization
## Setup remote developer environment shell profile (devenv/bash-profile)
# [KohaLXC]:devenv
# - [TODO]: Remove from here after checking this works from 'common' role!
# - [TODO]: Check KOHALXC_ vars have correct paths (should be in Works)
# - default settings for 'KohaLXC' are in: 'roles/common/defauls/main.yaml'
# - kohalxc_devenv (local) configs are in: '[kohalxc_tooldir]/conf.d/env.dev'
#- name: devenv - Setup system-wide Bash profile for remote KohaLXC-development
#  become: yes
#  template: >
#    src="files/devenv/bash_profile.sh.j2"
#    dest="/etc/profile.d/kohalxc-devenv.sh"
#    backup="no"
#  when:
#    - hostnode_devenv_enabled
#    - hostnode_environment != "localdev"

## Ensure kohahosts_operuser (devops/HOME) has required dirs
- name: srvenv - Ensure devops has dirs for scripts, logs and Works
  file: >
    path="/home/{{ hostnode_operuser }}/{{ item }}"
    state="directory"
  with_items:
    - bin
    - log
    - Works

## Ensure KohaLXC and data/setup dirs in devops Works exist (synch it all always)
- name: srvenv - Ensure Works contents exist (sync always afterwards) for KohaLXC-tools/setups
  file: >
    path="{{ hostnode_kohalxc_works }}/{{ item }}"
    state="directory"
    mode="g+s,o-rwx"
    group="{{ hostnode_kohagrp_id }}"
    recurse="no"
  with_items:
    - KohaLXC
    - "{{ hostnode_kohalxc_organization | d('KohaSuomi') }}"
  notify: Sync kohalxc
  changed_when: true
#- debug: var="kohalxc_rootdir,hostnode_kohalxc_works,hostnode_srvenv_enabled"
## NOTE: Instead of using 'synchronize' task below as previously,
# - forcefully notify here handler to sync KohaLXC-contents to server/devops
# - e.g. KohaLXC-tools need to be in place for 'dataenv/mmtenv'-stuff later
# - can use '--force-handler' to ensure handler is called (atleast eventually)
- meta: flush_handlers

#- debug: var="hostnode_kohalxc_rootdir,hostnode_kohalxc_tooldir"
## Ensure devops/hostnode has required symlinks in $HOME
- name: srvenv - Symlink for 'kohalxc' main script in devops/HOME
  file: >
    src="{{ hostnode_kohalxc_rootdir }}/kohalxc.sh"
    dest="{{ '/home/'~hostnode_operuser~'/bin/kohalxc' }}"
    state="link"
    force="yes"
- name: srvenv - Symlink for 'kohasetup' script in devops/HOME
  file: >
    src="{{ hostnode_kohalxc_tooldir }}/kohasetup.sh"
    dest="{{ '/home/'~hostnode_operuser~'/bin/kohasetup' }}"
    state="link"
    force="yes"

## Does LVM/VG+LV for backups and misc data exist?
- name: backup - Check we have VG-'data' for server backups and misc data
  become: yes
  shell: lvdisplay | grep -q "LV Path.*/{{hostnode_lvmvg_data}}/{{hostnode_lvmlv_backup}}"
  register: found_hostnode_lvmlv_backup
  failed_when: found_hostnode_lvmlv_backup.rc == 2
  changed_when: found_hostnode_lvmlv_backup.rc == 1
  when:
    - ansible_host == hostnode_backupsrv

## Setup backup+data LVS in Backup-server VG
- name: backup - Setup backup and data LVs in Backup server VG-data
  become: yes
  lvol: >
    vg="{{ hostnode_lvmvg_data }}"
    lv="{{ item.lv }}"
    size="{{ item.size }}"
    opts="-v"
    state="present"
  with_items:
    - { lv: "{{hostnode_lvmlv_backup}}", size: "{{hostnode_lvmlv_backup_size}}" }
    - { lv: "{{hostnode_lvmlv_data}}", size: "{{hostnode_lvmlv_data_size}}" }
  when:
    - ansible_host == hostnode_backupsrv
    - hostnode_lvmvg_data is defined
    - found_hostnode_lvmlv_backup.rc != 0

## Create LV-filesystem in Backup-server VG for backups+data
#- e.g. "shell: mkfs.ext4 /dev/roidata/backup"
- name: backup - Create filesystem in for VG-'data' LVs (backup+data)
  become: yes
  filesystem: >
    fstype="{{ hostnode_lvmlv_data_fs | d('ext4') }}"
    dev="/dev/{{ hostnode_lvmvg_data }}/{{ item }}"
    resizefs="yes"
    force="no"
  with_items:
    - "{{ hostnode_lvmlv_backup }}"
    - "{{ hostnode_lvmlv_data }}"
  when:
    - ansible_host == hostnode_backupsrv
    - hostnode_lvmvg_data is defined
    - found_hostnode_lvmlv_backup.rc != 0

## Mount LV-filesystems in Backup-server VG
- name: backup - Mount LV-fileystem(s) in Backup server VG
  become: yes
  mount: >
    name="{{ hostnode_backup_rootdir }}/{{ item }}"
    src="/dev/{{ hostnode_lvmvg_data }}/{{ item }}"
    fstype="{{ hostnode_lvmlv_data_fs | d('ext4') }}"
    opts="users,rw"
    state="mounted"
  with_items:
    - "{{ hostnode_lvmlv_backup }}"
    - "{{ hostnode_lvmlv_data }}"
  when:
    - ansible_host == hostnode_backupsrv
    - hostnode_lvmvg_data is defined

## Correct the Backup-related directory permissions and symlink them
- name: backup - Correct perms for Backup(s) locations
  become: yes
  shell: |
    chgrp koha {{ hostnode_backup_rootdir | d('/vol') }}/* && chmod g+w,o-rwx {{ hostnode_backup_rootdir | d('/vol') }}/*
    MP={{item}} && [[ ! -L /${MP^} ]] && ln -s {{ hostnode_backup_rootdir}}/$MP /${MP^}
    exit 0
  args:
    executable: /bin/bash
  with_items:
    - "{{ hostnode_lvmlv_backup }}"
    - "{{ hostnode_lvmlv_data }}"
  when:
    - ansible_host == hostnode_backupsrv
    - hostnode_backup_rootdir is defined
    - ("vol" in hostnode_backup_rootdir)

## Enable Backup-locations using 'sshfs' (e.g. from 'ansible_host' to backupsrv)
# - step 1 / 5: Unmount any existing mount points in client..
- name: backup(sshfs) - Ensure backup/source is unmounted from backup/target
  become: yes
  shell: mount | grep -q {{ hostnode_backup_clientpath | d('/mnt/Backup@remote') }} || exit 0 && umount {{ hostnode_backup_clientpath | d('/mnt/Backup@remote') }}
  when:
    - ansible_host != hostnode_backup_sshfssrv

# - step 2 / 5: Ensure we have the mount point in client..
- name: backup(sshfs) - Ensure the mount-point for backup/target exist
  become: yes
  file: >
    path="{{ hostnode_backup_clientpath | d('/mnt/Backup@remote') }}"
    state="directory"
    owner="{{ hostnode_operuser }}"
  when:
    - ansible_host != hostnode_backup_sshfssrv

# - step 3 / 5: Ensure we have required access keys for remote backup/mounting..
- name: backup(sshfs) - Ensure backup/source auth-key is in backup/target
  environment:
    SSHPASS: "{{ hostnode_operpass }}"
  shell: sshpass -e ssh-copy-id -o 'StrictHostKeyChecking=no' -i /home/{{ hostnode_operuser }}/.ssh/id_rsa.pub {{ hostnode_operuser }}@{{ hostnode_backupsrv }}
  when:
    - ansible_host != hostnode_backup_sshfssrv

# - step 4 / 5: Mount the remote backup..
- name: backup(sshfs) - Mount remote backup/target location
  shell: /usr/bin/sshfs -o reconnect {{ hostnode_operuser }}@{{ hostnode_backup_sshfssrv | d(hostnode_backupsrv) }}:{{ hostnode_backup_backupdir | d('Backup') }}/ {{ hostnode_backup_clientpath | d('/mnt/Backup@remote') }}
  when:
    - ansible_host != hostnode_backup_sshfssrv

# - step 5 / 5: Synlink mounted backup target to proper filesystem location..
# - TODO: Do we need this? (In the client better not have same folder as in server)
#- name: backup(sshfs) - Symlink for '/Backup' to mounted target location
#  become: yes
#  file: >
#    src="{{ hostnode_backup_clientpath | d('/mnt/Backup@remote') }}"
#    dest="/Backup"
#    state="link"
#    force="yes"
#  when:
#    - ansible_host != hostnode_backup_sshfssrv

## Ensure only latest kernels are kept
- name: srvenv - Ensure only latest kernels are kept (cleanup /boot)
  become: yes
  shell: purge-old-kernels --keep 3 -y
  #shell: apt purge $(dpkg --list 'linux-image*' | grep ^ii | awk '{print $2}' | sort | egrep "[0-9]-generic" | head -n -3 | tr '\n' ' '; echo "")
  args:
    executable: /bin/bash
  register: cmd_purge_oldkernels
#- debug: var=cmd_purge_oldkernels.cmd,cmd_purge_oldkernels.stdout_lines

## Make sure hosts package cache is not stale
- name: srvenv - Autoclean and update apt cache (kept valid for past 2 hrs)
  become: yes
  apt:
    autoremove: yes
    purge: yes
    force: yes
    update_cache: yes
  register: cmd_apt_autoremove
- debug: var=cmd_apt_autoremove

#    cache_valid_time: 7200
#when: ansible_os_family == 'Debian'
#- debug: var=ansible_os_family

## Recover from partial/failed upgrades and ensure only latest kernels are kept
- name: srvenv - Try to recover from partial installs (if any)
  become: yes
  shell: apt-get -f install
  register: cmd_aptget_recoverpartials
  failed_when:
    - cmd_aptget_recoverpartials.rc == 100

## List packages that need to be updated/upgraded in the server
- name: srvenv - List what is updatable/upgradable (sans held/ignored packages)
  shell: apt list --upgradable 2>/dev/null | grep -v '{{ hostnode_upgrade_pckgsignore | d() }}' | grep -s "upgradable"
  register: cmd_aptlist_upgrades
  failed_when: cmd_aptlist_upgrades.stderr != ""
  changed_when: cmd_aptlist_upgrades.rc == 0

- debug: var=hostnode_upgrade_enabled,hostnode_reboot_enabled,hostnode_dataenv_enabled
## Upgrade all packages
- name: srvenv - Upgrade all packages to the latest version.
  become: yes
  shell: apt clean && apt update -y && apt upgrade -y
  when:
    - hostnode_upgrade_enabled
    - cmd_aptlist_upgrades.rc == 0
  changed_when: cmd_aptlist_upgrades.rc == 0

## Persist current iptables rules
- name: Persist iptables rules (if upgrades and possible reboot so requires)
  become: yes
  shell: >
    service netfilter-persistent save
  when:
    - hostnode_reboot_enabled
    - cmd_aptlist_upgrades.rc == 0

## Reboot server
- name: srvenv - Reboot server (when package upgrade so requires)
  become: yes
  shell: >
    sleep 5 && /sbin/shutdown -r now "KohaLXC/Ansible update/upgrade triggered reboot."
    removes="/var/run/reboot-required"
  async: 1
  poll: 0
  when:
    - hostnode_reboot_enabled
  # [TODO]: keep below commented-out for reboots also when not upgrading..
  #  - cmd_aptlist_upgrades.rc == 0
  ignore_errors: true

## Wait for server to come back on-line
# [KohaLXC]:srvenv
- name: srvenv - Wait for server to get online after reboot
  become: no
  local_action: >
    wait_for host="{{ ansible_host }}"
    state=started
    port="{{ hostnode_sshport | d('22') }}"
    delay=10
    timeout=300
    connect_timeout=5
  when:
    - hostnode_reboot_enabled
  # [TODO]: keep below commented-out for reboots also when not upgrading..
  #  - cmd_aptlist_upgrades.rc == 0
