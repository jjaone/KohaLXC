---
# File: roles/hostnode/tasks/srvenv-setup.yaml
# #############################################################################
# Code is part of the KohaLXC/kohatools Ansible/Bash tooling environment
# for Koha/ILS-development, deployment & database conversion/migration tasks.
# Author: Jukka Aaltonen, Koha-Lappi, Rovaniemi City Library, Lapland/Finland.
# License: GNU General Public License version 3.
# 
# Description: "srvenv-setup"
# - setup hostnodes server-environment in playbook inventories
# - users and groups for 'dataenv' and 'devenv'
# - OS, distro, kernel (base installation of Ubuntu 16.04 LTS Server required)
# - timezone, localizations
# - filesystems: lvm, btrfs, zfs
# - network: iptables rules
# - apt packages: upgrade and update settings
# ##############################################################################

## Ensure env.* pckgs are installed
# [KohaLXC]: srvenv: Packages for server environment
- name: srvenv - Ensure all needed pckgs are installed
  become: yes
  apt: >
    name="{{ item }}"
    update_cache="yes"
    state="present"
    autoremove="yes"
  with_flattened:
    - hostnode_srvenv_pckgs
    - hostnode_secure_pckgs
  when:
    - hostnode_srvenv_enabled or hostnode_secure_enabled

## Ensure 'kohasys'-user exists (by default: kohasys/1000)
# [KohaLXC]:srvenv
- name: srvenv - Make system user 'kohasys' for Koha/hosts-service management
  become: yes
  user: >
    name="{{ hostnode_kohasys_user }}"
    uid="{{ hostnode_kohasys_id }}"
    state="present"
    generate_ssh_key="yes"
    comment="Koha/LXC system user"
  when:
    - hostnode_kohasys_user is defined
    - hostnode_kohasys_id is defined

## Ensure 'koha'-user (rssh) exists (by default: koha/1001)
# [KohaLXC]:dataenv
- name: dataenv - Ensure user 'koha' (rssh) exists for Koha-data & transfers
  become: yes
  user: >
    name="{{ hostnode_kohagrp_name }}"
    uid="{{ hostnode_kohagrp_id }}"
    group="{{ hostnode_kohagrp_name }}"
    state="present"
    shell="/usr/bin/rssh"
    generate_ssh_key="no"
    comment="Koha/LXC visitor user"
  when:
    - hostnode_dataenv_enabled
    - hostnode_kohagrp_name is defined
    - hostnode_kohagrp_id is defined

## Setup remote data environment rssh.conf (dataenv/rssh settings)
# [KohaLXC]:dataenv(!local) 
# - settings for 'KohaLXC' are in roles/common/defauls/main.yaml
# - kohalxc_dataenv == kohalxc_tooldir/conf.d/env.data
- name: dataenv - Setup system-wide rssh config for remote KohaLXC/dataenv
  become: yes
  template: >
    src="files/kohalxc_dataenv/rssh.conf.j2"
    dest="/etc/rssh.conf"
    backup="no"
  when:
    - hostnode_dataenv_enabled
    - hostnode_environment != "localdev"

## Ensure 'koha'-group exists (by default: koha/1001)
# [KohaLXC]:dataenv
- name: dataenv - Ensure group 'koha' exists for Koha-data & transfers
  become: yes
  group: >
    name="{{ hostnode_kohagrp_name }}"
    gid="{{ hostnode_kohagrp_id }}"
    state="present"
  when:
    - hostnode_dataenv_enabled
    - hostnode_kohagrp_name is defined
    - hostnode_kohagrp_id is defined

## Ensure devops (kohaoper/1002) belongs to 'koha' group and has ssh-keys
# [KohaLXC]:srvenv
- name: srvenv - Ensure devops has ssh-keys and belongs to 'koha' group
  become: yes
  user: >
    name="{{ hostnode_operuser }}"
    uid="{{ hostnode_operid }}"
    groups="{{ hostnode_kohagrp_name }}"
    append="yes"
    generate_ssh_key="yes"
    comment="Koha/LXC devops user"
  when:
    - hostnode_operuser is defined
    - hostnode_operid is defined
    - hostnode_kohagrp_name is defined

## Ensure locales we need are present
# [KOHALXC]:srvenv
- name: srvenv - Ensure needed locales for internationalization are present
  become: yes
  locale_gen:
    name: "{{ item }}"
    state: present
  with_items:
    - en_US.UTF-8
    - fi_FI.UTF-8

## Setup remote user environment shell profile (devenv/bash-profile)
# [KohaLXC]:devenv
# - settings for 'KohaLXC' are in roles/common/defauls/main.yaml
# - kohalxc_devenv == kohalxc_tooldir/conf.d/env.dev
- name: devenv - Setup system-wide Bash profile for remote KohaLXC/devenv
  become: yes
  template: >
    src="files/kohalxc_devenv/bash_profile.sh.j2"
    dest="/etc/profile.d/kohalxc-devenv.sh"
    backup="no"
  when:
    - hostnode_devenv_enabled
    - hostnode_environment != "localdev"

## Ensure kohahosts_operuser (devops/HOME) has required dirs
# [KOHALXC]:srvenv
- name: srvenv - Ensure devops has dirs for scripts, logs and Works
  file: >
    path="/home/{{ hostnode_operuser }}/{{ item }}"
    state="directory"
  with_items:
    - bin
    - log
    - Works
- name: srvenv - Ensure devops Works-subdirs exist for KohaLXC-tools setups (datasets)
  file: >
    path="{{ hostnode_kohalxc_works }}/{{ item }}"
    state="directory"
    mode="g+s,o-rwx"
    group="{{ hostnode_kohagrp_id }}"
    recurse="no"
  with_items:
    - KohaLXC
    - "{{ hostnode_kohalxc_organization | d('KohaSuomi') }}"

- debug: var=hostnode_dataenv_enabled,hostnode_dataenv_dataset
- debug: var=kohalxc_datadir,kohalxc_dataset
## Pull/extract any uploads of dataset dumps from datasrv/'koha'
# [KohaLXC]:dataenv
# -from: srv:/home/koha/Works/KohaLappi/{{item}}
# -to: local:{{ kohalxc_works }}/{{ kohalxc_organization }}/kohadata/"
# -item: hostnode_dataebv_datasets: e.g. "dump4mmt-Axiell-20161019-Lappi_PallasPro"
- name: dataenv - Pull (rsync) listed dataset dumps from server (to control host)
  synchronize: >
    mode="pull"
    src="/home/{{ hostnode_kohagrp_name | d('koha') }}/Works/{{ hostnode_kohalxc_organization }}/dump4mmt-{{ item }}"
    dest="{{ kohalxc_datadir }}"
    group="yes"
    perms="yes"
    recursive="yes"
    delete="no"
  with_items: "{{ hostnode_dataenv_dataset | d({}) }}"
  when:
    - hostnode_dataenv_enabled
    - kohalxc_datadir is defined
    - hostnode_dataenv_dataset is defined
    - hostnode_dataenv_dataset != ""

- debug: var=kohalxc_datadir,hostnode_dataenv_dataset
## Ensure dataset extraction and conv sources have required subdirs (local/control host)
# [KohaLXC]:dataenv(local)
- name: dataenv - Set required dirs and perms for dataset extraction and conv sources (control host)
  file: >
    path="{{ kohalxc_datadir }}/dump4mmt-{{ item.0 }}/source/{{ item.1 }}"
    state="directory"
    recurse="no"
    group="{{ hostnode_kohagrp_id }}"
    mode="u=rwx,g=rwxs,o-rwx"
  with_nested:
    - "{{ hostnode_dataenv_dataset | d({}) }}"
    - [ 'TranslationTables', 'preprocessed', 'scripts', 'target' ]
  when:
    - kohalxc_datadir is defined
    - hostnode_dataenv_enabled
    - item.0 is defined
  delegate_to: localhost

## Extract/uncompress listed dataset(s) from pulled archives, if any (local)
# [KohaLXC]:dataenv(local)
# - must use local action/gunzip cause no Ansible module for "uncompress" exists
# - Note: "shopt -s/-u nullglob" would work, but only with /bin/bash
- name: dataenv - Extract listed datasets/table data from pulled dumps (contol host)
  local_action: shell for f in {{ kohalxc_datadir }}/dump4mmt-{{ item }}/*.gz; do [ -f "$f" ] || continue; d=$(dirname $f); t=$(basename $f .gz); ( cd $d/source && test ! -f $t && gunzip -vc $f > $t || echo -n "$t," ); done
  with_items: "{{ hostnode_dataenv_dataset | d({}) }}"
  when:
    - hostnode_dataenv_enabled
    - kohalxc_datadir is defined

- debug: var=kohalxc_datadir,hostnode_dataenv_enabled,hostnode_dataenv_dataset,hostnode_ppmmtenv_enabled
## For 'liqlocde_translation.pm' (PP/MMT) extract source CSV from Google-docs/spreadsheet:
# [KohaLXC]:dataenv(local),ppmtenv
# - 'File id' and 'Sheet id' required (seems to work also w/o the &gid-argument in the URL)
- name: dataenv - Extract CSVs for PP/MMT-TranslationTables/licloqde_translation from Google-spreadsheet
  vars:
    org: "{{ hostnode_kohalxc_organization }}"
    gDocsUrl: "https://docs.google.com/spreadsheets/d"
    gFileId: "{{ kohalxc_dataenv_gfileid }}"
    gSheetId: "{{ kohalxc_dataenv_gsheetid }}"
    gExportFormat: "csv"
    srcName: liqlocde_translation
  uri:
    url: "{{ gDocsUrl }}/{{ gFileId }}/export?exportFormat={{ gExportFormat }}&gid={{ gSheetId }}"
    dest: "{{ kohalxc_datadir }}/dump4mmt-{{ item }}/{{ hostnode_dataenv_datasrc }}/TranslationTables/{{ srcName }}.csv"
    body_format: raw
    return_content: yes
  with_items: "{{ hostnode_dataenv_dataset | d({}) }}"
  when:
    - kohalxc_dataenv_gfileid is defined
    - hostnode_dataenv_enabled
    - kohalxc_datadir is defined
    - hostnode_ppmmtenv_enabled
  delegate_to: localhost

## For 'liqlocde_translation.pm' (PP/MMT) split source CSV from Google-docs/spreadsheet:
# [KohaLXC]:dataenv(local),ppmtenv
- name: dataenv - Fix delimiters and split source CSV by library id (first field)
  vars:
    srcName: liqlocde_translation
  local_action: shell cd {{ kohalxc_datadir }}/dump4mmt-{{ item }}/{{ hostnode_dataenv_datasrc }}/TranslationTables && rm -f {{ srcName }}-*.csv && cat {{ srcName }}.csv | tr ',' ';' | awk -F, 'NR>1 {print>"{{ srcName }}-" sprintf("%02d", $1) ".csv"}' && rm -f {{ kohalxc_tooldir }}/ppmmtws/PerlMMT/TranslationTables/{{ srcName }}.pm-map
  with_items: "{{ hostnode_dataenv_dataset | d({}) }}"
  when:
    - kohalxc_datadir is defined
    - kohalxc_tooldir is defined
    - hostnode_dataenv_enabled
    - hostnode_ppmmtenv_enabled

## Run locally (control host) the kohatools/ppmmtws/ConversionTools/makeliqlocde.sh
# [KohaLXC]:dataenv(local),ppmtenv
# - to generate the liqlocde_translation map for $org_unitsLappi (TranslationTable)
- name: dataenv - Generate '$org_Units' mapping for PP/MMT (TranslationTables/licloqde_translation.pm-map)
  vars:
    srcName: liqlocde_translation
  environment:
    KOHALXC_DATADIR: "{{ kohalxc_datadir }}"
    KOHALXC_DATASET: "{{ item }}"
  shell: "{{ kohalxc_tooldir }}/ppmmtws/ConversionTools/makeliqlocde.sh {{ srcName }}"
  args:
    chdir: "{{ kohalxc_tooldir }}/ppmmtws/ConversionTools"
    creates: "../PerlMMT/TranslationTables/{{ srcName }}.pm-map"
  with_items: "{{ hostnode_dataenv_dataset | d({}) }}"
  when:
    - kohalxc_datadir is defined
    - kohalxc_tooldir is defined
    - hostnode_dataenv_enabled
    - hostnode_ppmmtenv_enabled
  delegate_to: localhost
  notify: Sync kohalxc
## [TODO]: Instead of the 'synchronize' task below,
# - forcefully notify here handler to sync KohaLXC-contents to server/devops
# - e.g. KohaLXC-tools need to be in place for 'dataenv/mmtenv'-stuff later
# - can use '--force-handler' to ensure handler is called (atleast in the end)
- meta: flush_handlers

## [TODO]:
## Run locally (in control host) the "{{ kohalxc_datadir }}/{{ hostnode_dataenv_dataset }}/source/scripts/fix_source.sh"
# - to generate a fixed source *.kirs for iterating PP/MMT-runs
# - probabbly need to forcefully run 'Sync KohalXC' after this task..

- debug: var="hostnode_kohalxc_rootdir,hostnode_kohalxc_tooldir"
## Ensure devops/hostnode has required symlinks in $HOME
# [KohaLXC]:srvenv
- name: srvenv - Symlink for 'kohalxc' main script in devops/HOME
  file: >
    src="{{ hostnode_kohalxc_rootdir }}/kohalxc.sh"
    dest="{{ '/home/'~hostnode_operuser~'/bin/kohalxc' }}"
    state="link"
    force="yes"
- name: srvenv - Symlink for 'kohasetup' script in devops/HOME
  file: >
    src="{{ hostnode_kohalxc_tooldir }}/kohasetup.sh"
    dest="{{ '/home/'~hostnode_operuser~'/bin/kohasetup' }}"
    state="link"
    force="yes"

- debug: var=kohalxc_setupdir,kohalxc_datadir,hostnode_kohalxc_works,hostnode_dataenv_dataset,hostnode_mmtenv_enabled
## Push kohalxc/default setups and kohadata/dump4mtt-<dumpname>/source* datasets:
# [KohaLXC]:dataenv,mmtenv
# - to: /home/'hostnode_operuser'/Works/<org>/{kohalxc,kohadata}
- name: dataenv - Push KohaLXC lxc-setups & org datasets to operuser/Works 
  synchronize: >
    mode="push"
    src="{{ item }}"
    dest="{{ hostnode_kohalxc_works }}/{{ hostnode_kohalxc_organization }}"
    owner="no"
    group="yes"
    perms="yes"
    rsync_timeout="15"
    rsync_opts="--include='**/' --include='/*/default/**' --include='/*/dump4mmt-default**' --include='/*/dump4mmt-*/source*/**' --exclude='*'"
    recursive="yes"
    delete="no"
  with_items:
    - "{{ kohalxc_setupdir }}"
    - "{{ kohalxc_datadir }}"
  when:
    - hostnode_dataenv_enabled
    - hostnode_dataenv_dataset is defined
    - hostnode_dataenv_dataset != ""
    - hostnode_mmtenv_enabled

- debug: var="hostnode_kohalxc_tooldir,hostnode_ppmmtenv_enabled,hostnode_dataenv_datadir"
## Push/copy KohaLXC/mmtenv tools and templated default config.xml to target
# [KohaLXC]:dataenv,ppmmtenv
# Parameters passed to {host,lxc}_config.xml
# - name: name of the config file: {host_config,lxc_config}.xml
# - source: source directory in dump4mmt-??? folder ('source')
# - organization: library that we are MMT-converting
# - threadCount: number of threads MMT should use
# - debugACL: "DEBUGAuthoritiesCountLimit"
# - chunkSize,starting/endingChunk: number of records in MMT-biblios chunk (start/end)
# - loadExternalRepos: whether to load external repositories or not
# - preprocess: do the 'PreProcess' phase in each import chain
# - {biblios_,items_,holds_,fines_,patrons_,checkouts_,history_,serials_}run: Import chains
- name: dataenv - Push/copy MMT-tools host/lxc_config.xml to mmt/data-enabled targets (for MMT/LXCs)
  vars:
    host_src: "{{ hostnode_dataenv_datadir }}/dump4mmt-default/{{ hostnode_dataenv_datasrc }}"
    lxc_src: "/home/{{ kohalxc_operuser }}/kohadata/{{ hostnode_dataenv_datasrc }}"
    org: "{{ hostnode_kohalxc_organization }}"
  template: >-
    src="files/kohalxc_dataenv/config.xml.j2"
    dest="{{ hostnode_kohalxc_tooldir }}/ppmmtws/{{ item.name }}.xml"
    group="{{ hostnode_kohagrp_name }}"
    mode="g+w"
    backup="no"
  with_items:
    - { name: host_config, source: "{{ host_src }}", organization: "{{ org }}", threadCount: 0, debugACL: -7000, chunkSize: 5000, startingChunk: 0, endingChunk: -1, loadExternalRepos: 0, preprocess: 1, biblios_run: 1, items_run: 1, holds_run: 1, fines_run: 1, patrons_run: 1, checkouts_run: 1, history_run: 1, serials_run: 0 }
    - { name: lxc_config, source: "{{ lxc_src }}", organization: "{{ org }}", threadCount: 0, debugACL: -7000, chunkSize: 5000, startingChunk: 0, endingChunk: -1, loadExternalRepos: 0, preprocess: 1, biblios_run: 0, items_run: 0, holds_run: 0, fines_run: 0, patrons_run: 1, patrons_ssnindex: 120000, checkouts_run: 0, history_run: 0, serials_run: 0 }
#    - { name: configBiblios, source: "{{ src }}", organization: "{{ org }}", threadCount: 0, debugACL: -1000, chunkSize: 5000, startingChunk: 0, endingChunk: -1, loadExternalRepos: 0 }
  when:
    - hostnode_dataenv_enabled
    - hostnode_dataenv_datadir is defined
    - hostnode_ppmmtenv_enabled
    - hostnode_kohalxc_tooldir is defined

## Push/copy KohaLXC/mmtenv import.pl+TranslationTables to target
# [KohaLXC]:dataenv,ppmmtenv
- name: dataenv - Push/copy MMT-tools import.pl and TranslationTables to mmt-enabled targets (for MMT/LXCs)
  template: >-
    src="files/kohalxc_dataenv/{{ item.name }}.j2"
    dest="{{ hostnode_kohalxc_tooldir }}/ppmmtws/PerlMMT/{{ item.dir }}/{{ item.name }}"
    group="{{ hostnode_kohagrp_name }}"
    mode="g+w"
    backup="no"
  with_items:
    - { name: import.pl, dir: .}
    - { name: cutype_to_borrower_categorycode.pm, dir: TranslationTables }
    - { name: isil_translation.pm, dir: TranslationTables }
    - { name: liqlocde_translation.pm, dir: TranslationTables }
    - { name: material_code_to_itype.pm, dir: TranslationTables }
  when:
    - hostnode_dataenv_enabled
    - hostnode_dataenv_datadir is defined
    - hostnode_ppmmtenv_enabled
    - hostnode_kohalxc_tooldir is defined
  
## Push/copy KohaLXC/mmtenv lib and BibliosImportChain scripts/configs to target
# [KohaLXC]:dataenv,ppmmtenv
- name: dataenv - Push/copy MMT-tools 'lib' and '{Biblios,Patrons}ImportChain' scripts to ppmmt-enabled targets (for MMT/LXCs)
  template: >-
    src="files/kohalxc_dataenv/{{ item.name }}.j2"
    dest="{{ hostnode_kohalxc_tooldir }}/ppmmtws/PerlMMT/{{ item.dir }}/{{ item.name }}"
    group="{{ hostnode_kohagrp_name }}"
    mode="g+w"
    backup="no"
  with_items:
    - { name: BuildMARC.pm, dir: BibliosImportChain/FinMARC_Builder }
    - { name: Item.pm, dir: lib }
    - { name: MarcRepair.pm, dir: BibliosImportChain }
    - { name: Patron.pm, dir: lib }
    - { name: Record.pm, dir: lib/MARC }
    - { name: SharedDocidRecordsHandler.pm, dir: BibliosImportChain/FinMARC_Builder }
    - { name: Instructions.pm, dir: PatronsImportChain }
  when:
    - hostnode_dataenv_enabled
    - hostnode_dataenv_datadir is defined
    - hostnode_ppmmtenv_enabled
    - hostnode_kohalxc_tooldir is defined
  
## Make sure hosts package cache is not stale
# [KohaLXC]:srvenv
- name: srvenv - Update apt cache (kept valid for past 4 hrs)
  become: yes
  apt:
    update_cache: yes
    cache_valid_time: 7200
  when: ansible_os_family == 'Debian'

## List packages that need to be updated/upgraded in the server
# [KohaLXC]:srvenv
- name: srvenv - List what is updatable/upgradable (sans held/ignored packages)
  shell: apt list --upgradable 2>/dev/null | grep -v '{{ hostnode_upgrade_pckgsignore | d() }}' | grep -s "upgradable"
  register: cmd_aptlist_upgrades
  failed_when: cmd_aptlist_upgrades.stderr != ""
  changed_when: cmd_aptlist_upgrades.rc == 0

- debug: var=hostnode_upgrade_enabled,hostnode_reboot_enabled,hostnode_dataenv_enabled
## Upgrade all packages
# [KohaLXC]:srvenv
- name: srvenv - Upgrade all packages to the latest version.
  become: yes
  shell: apt clean && apt update -y && apt upgrade -y
  when:
    - hostnode_upgrade_enabled
    - cmd_aptlist_upgrades.rc == 0
  changed_when: cmd_aptlist_upgrades.rc == 0

## Reboot server
# [KohaLXC]:srvenv
- name: srvenv - Reboot server (when package upgrade so requires)
  become: yes
  shell: >
    sleep 5 && /sbin/shutdown -r now "KohaLXC/Ansible update/upgrade triggered reboot."
    removes="/var/run/reboot-required"
  async: 1
  poll: 0
  when:
    - hostnode_reboot_enabled
  # [TODO]: keep below commented-out for reboots to work alsoe when not upgrading..    
  #  - cmd_aptlist_upgrades.rc == 0
  ignore_errors: true

## Wait for server to come back on-line
# [KohaLXC]:srvenv
- name: srvenv - Wait for server to get online after reboot
  become: no
  local_action: >
    wait_for host="{{ ansible_host }}"
    state=started
    port="{{ hostnode_sshport | d('22') }}"
    delay=10
    timeout=300
    connect_timeout=5
  when:
    - hostnode_reboot_enabled
  # [TODO]: keep below commented-out for reboots to work alsoe when not upgrading..    
  #  - cmd_aptlist_upgrades.rc == 0


